{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyNM7OeZRNbYLZCpfAh5OC4T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samdersson/Ecuaciones-no-lineales/blob/main/ecuaciones_no_lineales.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# metodo de Newto-Rpahson"
      ],
      "metadata": {
        "id": "z130jAPDrR8d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicio 1"
      ],
      "metadata": {
        "id": "FeqSH4n6rciK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym7cyiVnoLo0",
        "outputId": "55dc3c23-83fa-4d1d-d7f1-c0ad854ddd8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " El método no converge después de 100 iteraciones\n",
            "Pesos y bias óptimos: [16.50321348 -8.42153708 -6.0816764 ]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definimos la función de error como una función no lineal de los pesos w1, w2 y b\n",
        "def error(X):\n",
        "    w1, w2, b = X\n",
        "    return np.array([\n",
        "        np.exp(w1) + w2 + b - 1,  # Primera ecuación que involucra los pesos\n",
        "        w1**2 + w2**2 - 4,  # Segunda ecuación (penaliza valores altos de los pesos)\n",
        "        w1 + w2 + b - 2  # Tercera ecuación (regularización simple)\n",
        "    ])\n",
        "\n",
        "# Jacobiano de la función de error (derivadas parciales con respecto a los pesos)\n",
        "def jacobiano(X):\n",
        "    w1, w2, b = X\n",
        "    return np.array([\n",
        "        [np.exp(w1), 1, 1],  # Derivada de la primera ecuación respecto a w1, w2 y b\n",
        "        [2*w1, 2*w2, 0],  # Derivada de la segunda ecuación respecto a w1, w2 y b\n",
        "        [1, 1, 1]  # Derivada de la tercera ecuación respecto a w1, w2 y b\n",
        "    ])\n",
        "\n",
        "# Método de Newton-Raphson para encontrar los pesos óptimos\n",
        "def newton_raphson(error, J, X0, tol=1e-6, max_iter=100):\n",
        "    X = X0\n",
        "    for i in range(max_iter):\n",
        "        J_inv = np.linalg.inv(J(X))  # Invertir el jacobiano en el punto actual\n",
        "        F_val = error(X)  # Evaluar la función de error en el punto actual\n",
        "        X_new = X - np.dot(J_inv, F_val)  # Actualizar los pesos\n",
        "        if np.linalg.norm(X_new - X, ord=np.inf) < tol:  # Verificar convergencia\n",
        "            return X_new\n",
        "        X = X_new  # Actualizar los pesos actuales\n",
        "    print (\" El método no converge después de {} iteraciones\".format(max_iter))\n",
        "    return X\n",
        "\n",
        "# Estimación inicial de los pesos y bias\n",
        "X0 = np.array([0.5, 0.5, 0.5])\n",
        "# Llamada al método de Newton-Raphson para minimizar el error\n",
        "solucion = newton_raphson(error, jacobiano, X0)\n",
        "print(\"Pesos y bias óptimos:\", solucion)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Método de Broyden"
      ],
      "metadata": {
        "id": "mJmonTN0s8tT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import broyden1\n",
        "\n",
        "# Función de error no lineal\n",
        "def error(X):\n",
        "    w1, w2, b = X\n",
        "    return np.array([\n",
        "        w1**2 + w2**2 + b**2 - 5,  # Función de error sobre los pesos\n",
        "        np.tanh(w1) + w2 + b - 1,  # Función de activación no lineal\n",
        "        w1 + w2 + b - 2  # Regularización simple\n",
        "    ])\n",
        "\n",
        "# Método de Broyden sin calcular derivadas explícitamente\n",
        "X0 = np.array([1.0, 1.0, 1.0])  # Estimación inicial de los pesos\n",
        "solucion = broyden1(error, X0, f_tol=1e-6)  # Uso del método de Broyden\n",
        "print(\"Pesos óptimos:\", solucion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plHRIYBbs9AS",
        "outputId": "6a6cd511-6b37-4cc4-d317-743b050004ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pesos óptimos: [ 1.9611792  -0.7398733   0.77869377]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Método de Punto Fijo"
      ],
      "metadata": {
        "id": "YTjvahs4tPF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definimos la función de ajuste para el método de punto fijo\n",
        "def G(X):\n",
        "    w1, w2, b = X\n",
        "    return np.array([\n",
        "        np.sqrt(4 - w2**2),  # Aproximación para w1\n",
        "        1 - np.exp(w1),  # Aproximación para w2\n",
        "        w1 + w2 - 2  # Aproximación para b\n",
        "    ])\n",
        "\n",
        "# Método de Punto Fijo para ajustar los pesos\n",
        "def punto_fijo(G, X0, tol=1e-6, max_iter=100):\n",
        "    X = X0\n",
        "    for i in range(max_iter):\n",
        "        X_new = G(X)  # Aplicar la función G para actualizar los pesos\n",
        "        if np.linalg.norm(X_new - X, ord=np.inf) < tol:  # Verificar convergencia\n",
        "            return X_new\n",
        "        X = X_new  # Actualizar los pesos actuales\n",
        "    print (\"warnning: El método no converge después de {} iteraciones\".format(max_iter))\n",
        "    return X\n",
        "\n",
        "# Estimación inicial de los pesos\n",
        "X0 = np.array([1.0, 1.0, 1.0])\n",
        "# Llamada al método de punto fijo para ajustar los pesos\n",
        "solucion = punto_fijo(G, X0)\n",
        "print(\"Pesos óptimos:\", solucion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cwim8qBWtU4C",
        "outputId": "cee2fa4c-da05-4115-d3e3-6b8a64bf37f9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "warnning: El método no converge después de 100 iteraciones\n",
            "Pesos óptimos: [nan nan nan]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-1fc3c9ea3c5f>:7: RuntimeWarning: invalid value encountered in sqrt\n",
            "  np.sqrt(4 - w2**2),  # Aproximación para w1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Método de la Secante Multivariable"
      ],
      "metadata": {
        "id": "VVW9Hn5hvZQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importamos las librerias necesarias en este caso solo es una\n",
        "import numpy as np\n",
        "\n",
        "# Definimos la función de error que depende de los pesos w1, w2 y el bias b\n",
        "def error(X):\n",
        "    w1, w2, b = X\n",
        "    return np.array([\n",
        "        w1**2 + w2**2 + b**2 - 5,  # Función de error (penaliza grandes valores de los pesos)\n",
        "        np.tanh(w1) + w2 + b - 1,  # Activación no lineal con tangente hiperbólica\n",
        "        w1 + w2 + b - 2  # Regularización simple\n",
        "    ])\n",
        "\n",
        "# Método de la Secante Multivariable\n",
        "def secante_multivariable(F, X0, X1, tol=1e-6, max_iter=100):\n",
        "    for i in range(max_iter):\n",
        "        F0, F1 = F(X0), F(X1)  # Evaluamos la función de error en X0 y X1\n",
        "        diff = X1 - X0  # Diferencia entre X1 y X0\n",
        "        delta_F = F1 - F0  # Diferencia entre F(X1) y F(X0)\n",
        "\n",
        "        if np.linalg.norm(delta_F, ord=np.inf) < tol:  # Si la diferencia es pequeña, hemos convergido\n",
        "            return X1\n",
        "\n",
        "        # Actualización de los parámetros\n",
        "        X2 = X1 - np.dot(diff, F1) / np.dot(delta_F, delta_F) * delta_F\n",
        "        X0, X1 = X1, X2  # Actualizamos las estimaciones para la siguiente iteración\n",
        "\n",
        "    raise ValueError(\"El método no converge después de {} iteraciones\".format(max_iter))\n",
        "\n",
        "# Estimación inicial de los pesos y bias\n",
        "X0 = np.array([1.0, 1.0, 1.0])  # Primer punto\n",
        "X1 = np.array([0.9, 0.9, 0.9])  # Segundo punto cercano al primero\n",
        "\n",
        "# Aplicamos el método de la secante multivariable\n",
        "solucion = secante_multivariable(error, X0, X1)\n",
        "print(\"Pesos y bias óptimos:\", solucion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLw0e9UCvfx0",
        "outputId": "be8e55dc-8bf3-4a40-9e1f-aa0d6975a7e3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pesos y bias óptimos: [1.28610341 1.04218462 1.09962675]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ETj6wMP6wVja"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}